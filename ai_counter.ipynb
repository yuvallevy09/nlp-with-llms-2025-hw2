{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e9d1d3",
   "metadata": {},
   "source": [
    "# DSPy Simple Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34733789",
   "metadata": {},
   "source": [
    "### From https://x.com/MaximeRivest/article/1929861781448536081 \n",
    "### Maxime Rivest May 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ea257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! uv pip install dspy\n",
    "#! uv pip install attachments \"datar[pandas]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fc76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datar.dplyr import mutate, summarise, n\n",
    "from datar.tibble import tibble\n",
    "import datar.base as b\n",
    "from datar import f\n",
    "from attachments import Attachments\n",
    "import dspy\n",
    "\n",
    "lm = dspy.LM('ollama_chat/devstral', api_base='http://localhost:11434', api_key='')\n",
    "# lm=dspy.LM('xai/grok-3-mini')\n",
    "dspy.configure(lm=lm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ddedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup dspy program\n",
    "class count_ai_occurrences(dspy.Signature):\n",
    "    \"\"\"Count the number times the word 'Artificial Intelligence' or 'AI' or any other reference to AI or AI-related terms appears\n",
    "       in the paragraph\"\"\"\n",
    "    paragraph: str= dspy.InputField(desc = \"The paragraph to count the AI mentions in\")\n",
    "    ai_occurrences_count: int= dspy.OutputField(desc = \"The number of times the word 'Artificial Intelligence' or 'AI' appears in the paragraph\")\n",
    "\n",
    "dspy_module = dspy.Predict(count_ai_occurrences)\n",
    "\n",
    "def count_ai_occurrences_f(paragraph):\n",
    "    return dspy_module(paragraph=paragraph).ai_occurrences_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a7a75390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fetches the AI wikipedia page and splits it into paragraphs\n",
    "attachments_dsl = \"[images: false][select: p,title,h1,h2,h3,h4,h5,h6][split: paragraphs]\"\n",
    "a = Attachments(\"https://en.wikipedia.org/wiki/Artificial_intelligence\" + attachments_dsl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "afbe8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a dataframe with the paragraphs and the flash response\n",
    "df = (tibble(paragraphs = [p.text for p in a[:20]]) >>\n",
    "    mutate(flash_response= f.paragraphs.apply(count_ai_occurrences_f)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "042e5598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>flash_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th style=\"font-style: italic;\" ></th>\n",
       "      <td style=\"font-style: italic;\" >&lt;object&gt;</td>\n",
       "      <td style=\"font-style: italic;\" >&lt;int64&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># https://en.wikipedia.org/wiki/Artificial_int...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># Artificial intelligence - Wikipedia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>## Contents</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># Artificial intelligence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial intelligence (AI) is the capability...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>High-profile applications of AI include advanc...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Various subfields of AI research are centered ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Artificial intelligence was founded as an acad...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>## Goals</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The general problem of simulating (or creating...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>### Reasoning and problem-solving</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Early researchers developed algorithms that im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Many of these algorithms are insufficient for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>### Knowledge representation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Knowledge representation and knowledge enginee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A knowledge base is a body of knowledge repres...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Among the most difficult problems in knowledge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>### Planning and decision-making</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>An \"agent\" is anything that perceives and take...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In classical planning, the agent knows exactly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "                                           paragraphs  flash_response\n",
       "                                             <object>         <int64>\n",
       "0   # https://en.wikipedia.org/wiki/Artificial_int...               2\n",
       "1               # Artificial intelligence - Wikipedia               1\n",
       "2                                         ## Contents               0\n",
       "3                           # Artificial intelligence               1\n",
       "4   Artificial intelligence (AI) is the capability...               3\n",
       "5   High-profile applications of AI include advanc...              10\n",
       "6   Various subfields of AI research are centered ...              10\n",
       "7   Artificial intelligence was founded as an acad...              10\n",
       "8                                            ## Goals               0\n",
       "9   The general problem of simulating (or creating...               2\n",
       "10                  ### Reasoning and problem-solving               0\n",
       "11  Early researchers developed algorithms that im...               0\n",
       "12  Many of these algorithms are insufficient for ...               2\n",
       "13                       ### Knowledge representation               0\n",
       "14  Knowledge representation and knowledge enginee...               1\n",
       "15  A knowledge base is a body of knowledge repres...               0\n",
       "16  Among the most difficult problems in knowledge...               1\n",
       "17                   ### Planning and decision-making               0\n",
       "18  An \"agent\" is anything that perceives and take...               0\n",
       "19  In classical planning, the agent knows exactly...               0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a column with the sonnet response, it will be used as the goldset\n",
    "with dspy.context(lm=dspy.LM('anthropic/claude-sonnet-4-20250514')):\n",
    "    df_with_goldset_col= mutate(df, resp_sonnet = f.paragraphs.apply(count_ai_occurrences_f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68d262cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th style=\"font-style: italic;\" ></th>\n",
       "      <td style=\"font-style: italic;\" >&lt;float64&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "   baseline_precision\n",
       "            <float64>\n",
       "0                70.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just printing the baseline precision\n",
    "(mutate(df_with_goldset_col, exact_match = f.resp_sonnet == f.flash_response) >>\n",
    "    summarise(baseline_precision = b.sum(f.exact_match)/n() * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "38c7c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data into a format that can be used for training\n",
    "trainset = []\n",
    "for r in df_with_goldset_col.to_dict(orient='records'):\n",
    "    trainset.append(dspy.Example(\n",
    "        paragraph=r['paragraphs'],           # this is the input\n",
    "        ai_occurrences_count=r[\"resp_sonnet\"]).  # this is the target\n",
    "       with_inputs('paragraph'))            # this is needed (not sure why)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b6c49e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metric for the optimizer\n",
    "def exact_match(x, y, trace=None): return x.ai_occurrences_count == y.ai_occurrences_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e69627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:20:17 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 10\n",
      "minibatch: False\n",
      "num_fewshot_candidates: 6\n",
      "num_instruct_candidates: 3\n",
      "valset size: 16\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mProjected Language Model (LM) Calls\u001b[0m\n",
      "\n",
      "Based on the parameters you have set, the maximum number of LM calls is projected as follows:\n",
      "\n",
      "\u001b[93m- Prompt Generation: \u001b[94m\u001b[1m10\u001b[0m\u001b[93m data summarizer calls + \u001b[94m\u001b[1m3\u001b[0m\u001b[93m * \u001b[94m\u001b[1m1\u001b[0m\u001b[93m lm calls in program + (\u001b[94m\u001b[1m2\u001b[0m\u001b[93m) lm calls in program-aware proposer = \u001b[94m\u001b[1m15\u001b[0m\u001b[93m prompt model calls\u001b[0m\n",
      "\u001b[93m- Program Evaluation: \u001b[94m\u001b[1m16\u001b[0m\u001b[93m examples in val set * \u001b[94m\u001b[1m10\u001b[0m\u001b[93m batches = \u001b[94m\u001b[1m160\u001b[0m\u001b[93m LM program calls\u001b[0m\n",
      "\n",
      "\u001b[93m\u001b[1mEstimated Cost Calculation:\u001b[0m\n",
      "\n",
      "\u001b[93mTotal Cost = (Number of calls to task model * (Avg Input Token Length per Call * Task Model Price per Input Token + Avg Output Token Length per Call * Task Model Price per Output Token)\n",
      "            + (Number of program calls * (Avg Input Token Length per Call * Task Prompt Price per Input Token + Avg Output Token Length per Call * Prompt Model Price per Output Token).\u001b[0m\n",
      "\n",
      "For a preliminary estimate of potential costs, we recommend you perform your own calculations based on the task\n",
      "and prompt models you intend to use. If the projected costs exceed your budget or expectations, you may consider:\n",
      "\n",
      "\u001b[93m- Reducing the number of trials (`num_trials`), the size of the valset, or the number of LM calls in your program.\u001b[0m\n",
      "\u001b[93m- Using a cheaper task model to optimize the prompt.\u001b[0m\n",
      "\u001b[93m- Setting `minibatch=True` if you haven't already.\u001b[0m\n",
      "\n",
      "To proceed with the execution of this program, please confirm by typing \u001b[94m'y'\u001b[0m for yes or \u001b[94m'n'\u001b[0m for no.\n",
      "If no input is received within 20 seconds, the program will proceed automatically.\n",
      "\n",
      "If you would like to bypass this confirmation step in future executions, set the \u001b[93m`requires_permission_to_run`\u001b[0m flag to \u001b[93m`False`\u001b[0m when calling compile.\n",
      "\n",
      "\u001b[93mAwaiting your input...\u001b[0m\n",
      "\n",
      "Do you wish to continue? (y/n): "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:20:37 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/06/09 09:20:37 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/06/09 09:20:37 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=6 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No input received within 20 seconds. Proceeding with execution...\n",
      "Bootstrapping set 1/6\n",
      "Bootstrapping set 2/6\n",
      "Bootstrapping set 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00, 660.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.08s/it]\n",
      "2025/06/09 09:20:52 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/06/09 09:20:52 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:21:05 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=3 instructions...\n",
      "\n",
      "2025/06/09 09:22:11 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/06/09 09:22:11 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Count the number times the word 'Artificial Intelligence' or 'AI' or any other reference to AI or AI-related terms appears in the paragraph\n",
      "\n",
      "2025/06/09 09:22:11 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Count the occurrences of \"AI\" or any reference to artificial intelligence in the given paragraph. Consider case insensitivity and variations like \"Artificial Intelligence,\" \"A.I.,\" etc.\n",
      "\n",
      "2025/06/09 09:22:11 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Analyze the given paragraph and return the number of occurrences where \"Artificial Intelligence,\" \"AI,\" or any related AI terms are mentioned. Ensure to count all direct and contextual references accurately.\n",
      "\n",
      "2025/06/09 09:22:11 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/06/09 09:22:11 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/06/09 09:22:11 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/06/09 09:22:11 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 10 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.00 / 16 (68.8%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 2579.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:22:11 INFO dspy.evaluate.evaluate: Average Metric: 11 / 16 (68.8%)\n",
      "2025/06/09 09:22:11 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 68.75\n",
      "\n",
      "/Users/michael/Library/CloudStorage/OneDrive-BGU/BGU/courses/anlp2025/dspy/.venv/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/06/09 09:22:11 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.00 / 16 (50.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:26<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:22:37 INFO dspy.evaluate.evaluate: Average Metric: 8 / 16 (50.0%)\n",
      "2025/06/09 09:22:37 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/06/09 09:22:37 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [68.75, 50.0]\n",
      "2025/06/09 09:22:37 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 68.75\n",
      "2025/06/09 09:22:37 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/09 09:22:37 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.00 / 16 (68.8%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:24<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:23:02 INFO dspy.evaluate.evaluate: Average Metric: 11 / 16 (68.8%)\n",
      "2025/06/09 09:23:02 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.75 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/06/09 09:23:02 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [68.75, 50.0, 68.75]\n",
      "2025/06/09 09:23:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 68.75\n",
      "2025/06/09 09:23:02 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/09 09:23:02 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.00 / 16 (75.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:27<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:23:30 INFO dspy.evaluate.evaluate: Average Metric: 12 / 16 (75.0%)\n",
      "2025/06/09 09:23:30 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 75.0\n",
      "2025/06/09 09:23:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 75.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/06/09 09:23:30 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [68.75, 50.0, 68.75, 75.0]\n",
      "2025/06/09 09:23:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/06/09 09:23:30 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/09 09:23:30 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.00 / 16 (75.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:31<00:00,  1.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:24:02 INFO dspy.evaluate.evaluate: Average Metric: 12 / 16 (75.0%)\n",
      "2025/06/09 09:24:02 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 75.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/06/09 09:24:02 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [68.75, 50.0, 68.75, 75.0, 75.0]\n",
      "2025/06/09 09:24:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/06/09 09:24:02 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/09 09:24:02 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.00 / 16 (68.8%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:33<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:24:36 INFO dspy.evaluate.evaluate: Average Metric: 11 / 16 (68.8%)\n",
      "2025/06/09 09:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.75 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/06/09 09:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [68.75, 50.0, 68.75, 75.0, 75.0, 68.75]\n",
      "2025/06/09 09:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/06/09 09:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/09 09:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.00 / 16 (68.8%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 2828.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:24:36 INFO dspy.evaluate.evaluate: Average Metric: 11 / 16 (68.8%)\n",
      "2025/06/09 09:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.75 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/06/09 09:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [68.75, 50.0, 68.75, 75.0, 75.0, 68.75, 68.75]\n",
      "2025/06/09 09:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/06/09 09:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/09 09:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.00 / 16 (68.8%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:31<00:00,  1.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:25:07 INFO dspy.evaluate.evaluate: Average Metric: 11 / 16 (68.8%)\n",
      "2025/06/09 09:25:07 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.75 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/06/09 09:25:07 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [68.75, 50.0, 68.75, 75.0, 75.0, 68.75, 68.75, 68.75]\n",
      "2025/06/09 09:25:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/06/09 09:25:07 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/09 09:25:07 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.00 / 16 (50.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:31<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:25:39 INFO dspy.evaluate.evaluate: Average Metric: 8 / 16 (50.0%)\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [68.75, 50.0, 68.75, 75.0, 75.0, 68.75, 68.75, 68.75, 50.0]\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.00 / 16 (68.8%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 3199.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:25:39 INFO dspy.evaluate.evaluate: Average Metric: 11 / 16 (68.8%)\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.75 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [68.75, 50.0, 68.75, 75.0, 75.0, 68.75, 68.75, 68.75, 50.0, 68.75]\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 10 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.00 / 16 (75.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 4089.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:25:39 INFO dspy.evaluate.evaluate: Average Metric: 12 / 16 (75.0%)\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 75.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [68.75, 50.0, 68.75, 75.0, 75.0, 68.75, 68.75, 68.75, 50.0, 68.75, 75.0]\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/09 09:25:39 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 75.0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the optimizer\n",
    "optimizer = dspy.MIPROv2(metric=exact_match)\n",
    "optimized_dspy_module = optimizer.compile(dspy_module, trainset=trainset, requires_permission_to_run=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "25e3b2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_ai_occurrences_opt(paragraph):\n",
    "    return optimized_dspy_module(paragraph=paragraph).ai_occurrences_count\n",
    "\n",
    "# That's it with DSPy, you can use the optimized model like this:\n",
    "count_ai_occurrences_opt(\"This is about Deep Neural Networks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "77569b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The precision increased by 10.00% ðŸ”¥'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Datar to calculate the performance of the optimized model\n",
    "final_performance = (df_with_goldset_col >>\n",
    "mutate(\n",
    "        # Applies flash to every row with the optimized prompt\n",
    "        resp_flash_opt= f.paragraphs.apply(count_ai_occurrences_opt)) >>\n",
    "    mutate(\n",
    "        # Add 2 columns with 0 or 1 if the flash response is equal to the sonnet response\n",
    "        flash_eq_sonnet = f.resp_sonnet == f.flash_response,  # Compare flash with sonnet\n",
    "        flash_opt_eq_sonnet = f.resp_flash_opt == f.resp_sonnet  # Compare opt flash with sonnet\n",
    "        ) >>\n",
    "    summarise(\n",
    "        # Sum the number of rows where the flash response is equal to the sonnet response\n",
    "        flashlite_before_opt = b.sum(f.flash_eq_sonnet)/n() * 100, #n() is the number of rows in df\n",
    "        # Sum the number of rows where the opt flash response is equal to the sonnet response\n",
    "        flashlite_after_opt = b.sum(f.flash_opt_eq_sonnet)/n() * 100 #n() is the number of rows in df\n",
    "    ) >>\n",
    "    mutate(precision_increase=f.flashlite_after_opt-f.flashlite_before_opt)\n",
    "    )\n",
    "\n",
    "f\"The precision increased by {final_performance['precision_increase'].values[0]:.2f}% ðŸ”¥\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "920da892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predict(StringSignature(paragraph -> ai_occurrences_count\n",
       "    instructions='You are an expert AI text analyst. Given a paragraph of text, your task is to meticulously scan and count every occurrence of the terms \"Artificial Intelligence,\" \"AI,\" or any other related references, such as \"machine learning,\" \"neural networks,\" \"deep learning,\" or phrases that clearly allude to artificial intelligence concepts (e.g., in titles, URLs, or contextual mentions). Be thorough: consider variations in capitalization, abbreviations, and synonyms, but only count direct and unambiguous references. Return your response as: \"Total occurrences: [count]. Breakdown: [list of specific instances found].'\n",
       "    paragraph = Field(annotation=str required=True json_schema_extra={'desc': 'The paragraph to count the AI mentions in', '__dspy_field_type': 'input', 'prefix': 'Paragraph:'})\n",
       "    ai_occurrences_count = Field(annotation=int required=True json_schema_extra={'desc': \"The number of times the word 'Artificial Intelligence' or 'AI' appears in the paragraph\", '__dspy_field_type': 'output', 'prefix': 'Ai Occurrences Count:'})\n",
       "))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_dspy_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab110213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-03T22:11:18.601101]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `paragraph` (str): The paragraph to count the AI mentions in\n",
      "Your output fields are:\n",
      "1. `ai_occurrences_count` (int): The number of times the word 'Artificial Intelligence' or 'AI' appears in the paragraph\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## paragraph ## ]]\n",
      "{paragraph}\n",
      "\n",
      "[[ ## ai_occurrences_count ## ]]\n",
      "{ai_occurrences_count}        # note: the value you produce must be a single int value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        You are an expert AI text analyst. Given a paragraph of text, your task is to meticulously scan and count every occurrence of the terms \"Artificial Intelligence,\" \"AI,\" or any other related references, such as \"machine learning,\" \"neural networks,\" \"deep learning,\" or phrases that clearly allude to artificial intelligence concepts (e.g., in titles, URLs, or contextual mentions). Be thorough: consider variations in capitalization, abbreviations, and synonyms, but only count direct and unambiguous references. Return your response as: \"Total occurrences: [count]. Breakdown: [list of specific instances found].\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## paragraph ## ]]\n",
      "A knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.[23] Knowledge bases need to represent things such as objects, properties, categories, and relations between objects;[24] situations, events, states, and time;[25] causes and effects;[26] knowledge about knowledge (what we know about what other people know);[27] default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);[28] and many other aspects and domains of knowledge.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## ai_occurrences_count ## ]]` (must be formatted as a valid Python int), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## ai_occurrences_count ## ]]\n",
      "0\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-03T22:11:18.601299]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `paragraph` (str): The paragraph to count the AI mentions in\n",
      "Your output fields are:\n",
      "1. `ai_occurrences_count` (int): The number of times the word 'Artificial Intelligence' or 'AI' appears in the paragraph\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## paragraph ## ]]\n",
      "{paragraph}\n",
      "\n",
      "[[ ## ai_occurrences_count ## ]]\n",
      "{ai_occurrences_count}        # note: the value you produce must be a single int value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        You are an expert AI text analyst. Given a paragraph of text, your task is to meticulously scan and count every occurrence of the terms \"Artificial Intelligence,\" \"AI,\" or any other related references, such as \"machine learning,\" \"neural networks,\" \"deep learning,\" or phrases that clearly allude to artificial intelligence concepts (e.g., in titles, URLs, or contextual mentions). Be thorough: consider variations in capitalization, abbreviations, and synonyms, but only count direct and unambiguous references. Return your response as: \"Total occurrences: [count]. Breakdown: [list of specific instances found].\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## paragraph ## ]]\n",
      "Among the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous);[29] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).[16] There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.[c]\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## ai_occurrences_count ## ]]` (must be formatted as a valid Python int), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## ai_occurrences_count ## ]]\n",
      "1\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-03T22:11:18.601487]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `paragraph` (str): The paragraph to count the AI mentions in\n",
      "Your output fields are:\n",
      "1. `ai_occurrences_count` (int): The number of times the word 'Artificial Intelligence' or 'AI' appears in the paragraph\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## paragraph ## ]]\n",
      "{paragraph}\n",
      "\n",
      "[[ ## ai_occurrences_count ## ]]\n",
      "{ai_occurrences_count}        # note: the value you produce must be a single int value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        You are an expert AI text analyst. Given a paragraph of text, your task is to meticulously scan and count every occurrence of the terms \"Artificial Intelligence,\" \"AI,\" or any other related references, such as \"machine learning,\" \"neural networks,\" \"deep learning,\" or phrases that clearly allude to artificial intelligence concepts (e.g., in titles, URLs, or contextual mentions). Be thorough: consider variations in capitalization, abbreviations, and synonyms, but only count direct and unambiguous references. Return your response as: \"Total occurrences: [count]. Breakdown: [list of specific instances found].\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## paragraph ## ]]\n",
      "### Planning and decision-making\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## ai_occurrences_count ## ]]` (must be formatted as a valid Python int), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## ai_occurrences_count ## ]]\n",
      "0\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-03T22:11:18.601681]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `paragraph` (str): The paragraph to count the AI mentions in\n",
      "Your output fields are:\n",
      "1. `ai_occurrences_count` (int): The number of times the word 'Artificial Intelligence' or 'AI' appears in the paragraph\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## paragraph ## ]]\n",
      "{paragraph}\n",
      "\n",
      "[[ ## ai_occurrences_count ## ]]\n",
      "{ai_occurrences_count}        # note: the value you produce must be a single int value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        You are an expert AI text analyst. Given a paragraph of text, your task is to meticulously scan and count every occurrence of the terms \"Artificial Intelligence,\" \"AI,\" or any other related references, such as \"machine learning,\" \"neural networks,\" \"deep learning,\" or phrases that clearly allude to artificial intelligence concepts (e.g., in titles, URLs, or contextual mentions). Be thorough: consider variations in capitalization, abbreviations, and synonyms, but only count direct and unambiguous references. Return your response as: \"Total occurrences: [count]. Breakdown: [list of specific instances found].\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## paragraph ## ]]\n",
      "An \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.[d][32] In automated planning, the agent has a specific goal.[33] In automated decision-making, the agent has preferencesâ€”there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.[34]\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## ai_occurrences_count ## ]]` (must be formatted as a valid Python int), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## ai_occurrences_count ## ]]\n",
      "0\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-03T22:11:18.601877]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `paragraph` (str): The paragraph to count the AI mentions in\n",
      "Your output fields are:\n",
      "1. `ai_occurrences_count` (int): The number of times the word 'Artificial Intelligence' or 'AI' appears in the paragraph\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## paragraph ## ]]\n",
      "{paragraph}\n",
      "\n",
      "[[ ## ai_occurrences_count ## ]]\n",
      "{ai_occurrences_count}        # note: the value you produce must be a single int value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        You are an expert AI text analyst. Given a paragraph of text, your task is to meticulously scan and count every occurrence of the terms \"Artificial Intelligence,\" \"AI,\" or any other related references, such as \"machine learning,\" \"neural networks,\" \"deep learning,\" or phrases that clearly allude to artificial intelligence concepts (e.g., in titles, URLs, or contextual mentions). Be thorough: consider variations in capitalization, abbreviations, and synonyms, but only count direct and unambiguous references. Return your response as: \"Total occurrences: [count]. Breakdown: [list of specific instances found].\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## paragraph ## ]]\n",
      "In classical planning, the agent knows exactly what the effect of any action will be.[35] In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.[36]\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## ai_occurrences_count ## ]]` (must be formatted as a valid Python int), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## ai_occurrences_count ## ]]\n",
      "0\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

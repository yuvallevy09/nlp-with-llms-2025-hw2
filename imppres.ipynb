{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b8c418",
   "metadata": {},
   "source": [
    "# Exploring the ImpPres Dataset\n",
    "\n",
    "The https://huggingface.co/datasets/facebook/imppres dataset was introduced in *\"Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition\"*, Jeretivc et al, ACL 2020, https://www.aclweb.org/anthology/2020.acl-main.768\" to investigate the pragmatic inference capabilities of NLI models.\n",
    "\n",
    "It was created by synthesizing pairs (premise, hypothesis) according to different templates predicted by pragmatic analysis, for presuppositions triggered by different linguistic forms and implicatures of different forms.  Each sample is grouped in \"paradigms\" (groups of related pairs) that test the predicted relation between premise and hypothesis according to linguistic transformations.  For example, given a pair (premise, presupposition), the paradigm will include (negated-premise, presupposition), (question-premise, presupposition), (condition-premise, presupposition), (premise, negated-presupposition) etc.  If a model detects that the relation (premise, presupposition) is a form of \"presupposition entailment\", then it should consistently label the other members of the group according to linguistic predictions.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0227b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "sections = ['implicature_connectives', 'implicature_gradable_adjective', 'implicature_gradable_verb', 'implicature_modals', 'implicature_numerals_10_100', 'implicature_numerals_2_3', 'implicature_quantifiers', 'presupposition_all_n_presupposition', 'presupposition_both_presupposition', 'presupposition_change_of_state', 'presupposition_cleft_existence', 'presupposition_cleft_uniqueness', 'presupposition_only_presupposition', 'presupposition_possessed_definites_existence', 'presupposition_possessed_definites_uniqueness', 'presupposition_question_presupposition']\n",
    "\n",
    "\n",
    "imp_connectives = load_dataset(\"facebook/imppres\", sections[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "653292e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    connectives: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'gold_label_log', 'gold_label_prag', 'spec_relation', 'item_type', 'trigger', 'lexemes'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_connectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af2406d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'These computers or dresses would irritate Veronica.',\n",
       " 'hypothesis': \"These computers and dresses wouldn't both irritate Veronica.\",\n",
       " 'gold_label_log': 1,\n",
       " 'gold_label_prag': 0,\n",
       " 'spec_relation': 'implicature_PtoN',\n",
       " 'item_type': 'target',\n",
       " 'trigger': 'connective',\n",
       " 'lexemes': 'or - and'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_connectives['connectives'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a66c85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcos = load_dataset(\"facebook/imppres\", \"presupposition_change_of_state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c5fc6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a273020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    change_of_state: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "        num_rows: 1900\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c78f2797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'The guest had found John.',\n",
       " 'hypothesis': 'John used to be in an unknown location.',\n",
       " 'trigger': 'unembedded',\n",
       " 'trigger1': 'Not_In_Example',\n",
       " 'trigger2': 'Not_In_Example',\n",
       " 'presupposition': 'positive',\n",
       " 'gold_label': 0,\n",
       " 'UID': 'change_of_state',\n",
       " 'pairID': '0e',\n",
       " 'paradigmID': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcos['change_of_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e6ddd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "print(list(set([s['paradigmID'] for s in pcos['change_of_state']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02f9ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paradigm(dataset, paradigm_id):\n",
    "    return [s for s in dataset if s['paradigmID'] == paradigm_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28e5fea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'premise': 'The guest had found John.',\n",
       "  'hypothesis': 'John used to be in an unknown location.',\n",
       "  'trigger': 'unembedded',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'positive',\n",
       "  'gold_label': 0,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '0e',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest had found John.',\n",
       "  'hypothesis': \"John didn't used to be in an unknown location.\",\n",
       "  'trigger': 'unembedded',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'negated',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '1c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest had found John.',\n",
       "  'hypothesis': 'Peter used to be in an unknown location.',\n",
       "  'trigger': 'unembedded',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'neutral',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '2n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"The guest hadn't found John.\",\n",
       "  'hypothesis': 'John used to be in an unknown location.',\n",
       "  'trigger': 'negated',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'positive',\n",
       "  'gold_label': 0,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '3e',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"The guest hadn't found John.\",\n",
       "  'hypothesis': \"John didn't used to be in an unknown location.\",\n",
       "  'trigger': 'negated',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'negated',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '4c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"The guest hadn't found John.\",\n",
       "  'hypothesis': 'Peter used to be in an unknown location.',\n",
       "  'trigger': 'negated',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'neutral',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '5n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'Had the guest found John?',\n",
       "  'hypothesis': 'John used to be in an unknown location.',\n",
       "  'trigger': 'interrogative',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'positive',\n",
       "  'gold_label': 0,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '6e',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'Had the guest found John?',\n",
       "  'hypothesis': \"John didn't used to be in an unknown location.\",\n",
       "  'trigger': 'interrogative',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'negated',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '7c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'Had the guest found John?',\n",
       "  'hypothesis': 'Peter used to be in an unknown location.',\n",
       "  'trigger': 'interrogative',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'neutral',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '8n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest might have found John.',\n",
       "  'hypothesis': 'John used to be in an unknown location.',\n",
       "  'trigger': 'modal',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'positive',\n",
       "  'gold_label': 0,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '9e',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest might have found John.',\n",
       "  'hypothesis': \"John didn't used to be in an unknown location.\",\n",
       "  'trigger': 'modal',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'negated',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '10c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest might have found John.',\n",
       "  'hypothesis': 'Peter used to be in an unknown location.',\n",
       "  'trigger': 'modal',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'neutral',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '11n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"If the guest had found John, it's okay.\",\n",
       "  'hypothesis': 'John used to be in an unknown location.',\n",
       "  'trigger': 'conditional',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'positive',\n",
       "  'gold_label': 0,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '12e',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"If the guest had found John, it's okay.\",\n",
       "  'hypothesis': \"John didn't used to be in an unknown location.\",\n",
       "  'trigger': 'conditional',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'negated',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '13c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"If the guest had found John, it's okay.\",\n",
       "  'hypothesis': 'Peter used to be in an unknown location.',\n",
       "  'trigger': 'conditional',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'neutral',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '14n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"The guest hadn't found John.\",\n",
       "  'hypothesis': 'The guest had found John.',\n",
       "  'trigger': 'Not_In_Example',\n",
       "  'trigger1': 'negated',\n",
       "  'trigger2': 'unembedded',\n",
       "  'presupposition': 'Not_In_Example',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '15c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'Had the guest found John?',\n",
       "  'hypothesis': 'The guest had found John.',\n",
       "  'trigger': 'Not_In_Example',\n",
       "  'trigger1': 'interrogative',\n",
       "  'trigger2': 'unembedded',\n",
       "  'presupposition': 'Not_In_Example',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '16n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest might have found John.',\n",
       "  'hypothesis': 'The guest had found John.',\n",
       "  'trigger': 'Not_In_Example',\n",
       "  'trigger1': 'modal',\n",
       "  'trigger2': 'unembedded',\n",
       "  'presupposition': 'Not_In_Example',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '17n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"If the guest had found John, it's okay.\",\n",
       "  'hypothesis': 'The guest had found John.',\n",
       "  'trigger': 'Not_In_Example',\n",
       "  'trigger1': 'conditional',\n",
       "  'trigger2': 'unembedded',\n",
       "  'presupposition': 'Not_In_Example',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '18n',\n",
       "  'paradigmID': 0}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_paradigm(pcos['change_of_state'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "782499a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c535c9550c4f08bfffbe5fb4f96351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "presupposition_only_presupposition/only_(…):   0%|          | 0.00/38.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c012b9ed5cb448c8aad18365dbed6c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating only_presupposition split:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pop = load_dataset(\"facebook/imppres\", \"presupposition_only_presupposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2744d4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    only_presupposition: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "        num_rows: 1900\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfb1b19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    change_of_state: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "        num_rows: 1900\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68984aa",
   "metadata": {},
   "source": [
    "## Unify the Datasets\n",
    "\n",
    "Your task is to create a new dataset that \n",
    "* Has all the lines from the presupposition sections of ImprPres \n",
    "    * ['presupposition_all_n_presupposition', 'presupposition_both_presupposition', 'presupposition_change_of_state', 'presupposition_cleft_existence', 'presupposition_cleft_uniqueness', 'presupposition_only_presupposition', 'presupposition_possessed_definites_existence', 'presupposition_possessed_definites_uniqueness', 'presupposition_question_presupposition']\n",
    "* Has one more column which is the name of the section:\n",
    "    * ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID', 'section']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e059777",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f52e7105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd65d2af30dc4e1994e5969144a5d623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "presupposition_all_n_presupposition/all_(…):   0%|          | 0.00/43.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2026b6ea684f21bfa6841706cfd2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating all_n_presupposition split:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1900 rows from presupposition_all_n_presupposition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41b495849554a4991c2477ffc799a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "presupposition_both_presupposition/both_(…):   0%|          | 0.00/41.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcb5c7eefdf454abf76d9bf8a5842d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating both_presupposition split:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1900 rows from presupposition_both_presupposition\n",
      "Loaded 1900 rows from presupposition_change_of_state\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a4360120294b6b9c7f1aa5255b486a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "presupposition_cleft_existence/cleft_exi(…):   0%|          | 0.00/37.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161aa2af09664fa2b0a8aadf30fe14c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating cleft_existence split:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1900 rows from presupposition_cleft_existence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91be9e68279f4ec9a835ef0df339a559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "presupposition_cleft_uniqueness/cleft_un(…):   0%|          | 0.00/38.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9754860bba74027ba3877a4704a8ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating cleft_uniqueness split:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1900 rows from presupposition_cleft_uniqueness\n",
      "Loaded 1900 rows from presupposition_only_presupposition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52060c17cadf4c8aafe7a236331b79e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "presupposition_possessed_definites_exist(…):   0%|          | 0.00/38.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537a1aceb5564cea8e91751bdbefa378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating possessed_definites_existence split:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1900 rows from presupposition_possessed_definites_existence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885329b9d4ab4c9d85a011da9bd35879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "presupposition_possessed_definites_uniqu(…):   0%|          | 0.00/42.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac28f811ad74683931ee84d0de0e13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating possessed_definites_uniqueness split:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1900 rows from presupposition_possessed_definites_uniqueness\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d084902e12f14111aa0c83c18bce2aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "presupposition_question_presupposition/q(…):   0%|          | 0.00/41.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7202b393504f45d0afe15aa11c7c32f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating question_presupposition split:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1900 rows from presupposition_question_presupposition\n",
      "\n",
      "Unified dataset created:\n",
      "Total rows: 17100\n",
      "Columns: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID', 'section']\n",
      "Saved as 'unified_presupposition_dataset.csv'\n",
      "Expected columns present: True\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "import pandas as pd\n",
    "\n",
    "presupposition_sections = [\n",
    "    'presupposition_all_n_presupposition',\n",
    "    'presupposition_both_presupposition', \n",
    "    'presupposition_change_of_state',\n",
    "    'presupposition_cleft_existence',\n",
    "    'presupposition_cleft_uniqueness',\n",
    "    'presupposition_only_presupposition',\n",
    "    'presupposition_possessed_definites_existence',\n",
    "    'presupposition_possessed_definites_uniqueness',\n",
    "    'presupposition_question_presupposition'\n",
    "]\n",
    "\n",
    "# Load and combine all sections\n",
    "combined_data = []\n",
    "\n",
    "for section in presupposition_sections:\n",
    "    # Load dataset\n",
    "    dataset = load_dataset(\"facebook/imppres\", section)\n",
    "    dataset_key = list(dataset.keys())[0]\n",
    "    \n",
    "    # Convert to pandas and add section column\n",
    "    df = dataset[dataset_key].to_pandas()\n",
    "    df['section'] = section\n",
    "    \n",
    "    combined_data.append(df)\n",
    "    print(f\"Loaded {len(df)} rows from {section}\")\n",
    "\n",
    "# Combine all dataframes\n",
    "unified_df = pd.concat(combined_data, ignore_index=True)\n",
    "\n",
    "# Convert back to Hugging Face dataset\n",
    "from datasets import Dataset\n",
    "unified_dataset = Dataset.from_pandas(unified_df)\n",
    "\n",
    "print(f\"\\nUnified dataset created:\")\n",
    "print(f\"Total rows: {len(unified_dataset)}\")\n",
    "print(f\"Columns: {unified_dataset.column_names}\")\n",
    "\n",
    "# Save as CSV\n",
    "unified_df.to_csv('unified_presupposition_dataset.csv', index=False)\n",
    "print(\"Saved as 'unified_presupposition_dataset.csv'\")\n",
    "\n",
    "# Verify the expected columns are present\n",
    "expected_columns = ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', \n",
    "                   'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID', 'section']\n",
    "print(f\"Expected columns present: {set(expected_columns).issubset(set(unified_dataset.column_names))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef82769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy configured with Grok-3-mini\n",
      "Loading unified presupposition dataset...\n",
      "Loaded unified dataset with 17100 rows\n",
      "\n",
      "============================================================\n",
      "STEP 1: EXPLORING PARADIGM STRUCTURE\n",
      "============================================================\n",
      "Working with subset for initial exploration...\n",
      "Dataset overview:\n",
      "- Total samples: 1000\n",
      "- Unique paradigms: 53\n",
      "- Sections: ['presupposition_all_n_presupposition']\n",
      "\n",
      "Paradigm size distribution:\n",
      "12     1\n",
      "19    52\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Transformation analysis:\n",
      "- Unique 'trigger' values: ['Not_In_Example', 'conditional', 'interrogative', 'modal', 'negated', 'unembedded']\n",
      "- Unique 'trigger1' values: ['Not_In_Example', 'conditional', 'interrogative', 'modal', 'negated']\n",
      "- Unique 'trigger2' values: ['Not_In_Example', 'unembedded']\n",
      "- Unique 'presupposition' values: ['Not_In_Example', 'negated', 'neutral', 'positive']\n",
      "\n",
      "Label distribution:\n",
      "gold_label\n",
      "0    264\n",
      "1    420\n",
      "2    316\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- PARADIGM 0 (Section: presupposition_all_n_presupposition) ---\n",
      "Size: 19 samples\n",
      "  0e: trigger='unembedded', presupposition='positive', label=0\n",
      "    P: All ten guys that proved to boast were divorcing.\n",
      "    H: There are exactly ten guys that proved to boast.\n",
      "\n",
      "  10c: trigger='modal', presupposition='negated', label=2\n",
      "    P: All ten guys that proved to boast might have been divorcing.\n",
      "    H: There are exactly eleven guys that proved to boast.\n",
      "\n",
      "  11n: trigger='modal', presupposition='neutral', label=1\n",
      "    P: All ten guys that proved to boast might have been divorcing.\n",
      "    H: There are exactly ten senators that proved to boast.\n",
      "\n",
      "  12e: trigger='conditional', presupposition='positive', label=0\n",
      "    P: If all ten guys that proved to boast were divorcing, it's okay.\n",
      "    H: There are exactly ten guys that proved to boast.\n",
      "\n",
      "  13c: trigger='conditional', presupposition='negated', label=2\n",
      "    P: If all ten guys that proved to boast were divorcing, it's okay.\n",
      "    H: There are exactly eleven guys that proved to boast.\n",
      "\n",
      "  14n: trigger='conditional', presupposition='neutral', label=1\n",
      "    P: If all ten guys that proved to boast were divorcing, it's okay.\n",
      "    H: There are exactly ten senators that proved to boast.\n",
      "\n",
      "  15c: trigger='Not_In_Example', trigger1='negated', trigger2='unembedded', presupposition='Not_In_Example', label=2\n",
      "    P: All ten guys that proved to boast weren't divorcing.\n",
      "    H: All ten guys that proved to boast were divorcing.\n",
      "\n",
      "  16n: trigger='Not_In_Example', trigger1='interrogative', trigger2='unembedded', presupposition='Not_In_Example', label=1\n",
      "    P: Were all ten guys that proved to boast divorcing?\n",
      "    H: All ten guys that proved to boast were divorcing.\n",
      "\n",
      "  17n: trigger='Not_In_Example', trigger1='modal', trigger2='unembedded', presupposition='Not_In_Example', label=1\n",
      "    P: All ten guys that proved to boast might have been divorcing.\n",
      "    H: All ten guys that proved to boast were divorcing.\n",
      "\n",
      "  18n: trigger='Not_In_Example', trigger1='conditional', trigger2='unembedded', presupposition='Not_In_Example', label=1\n",
      "    P: If all ten guys that proved to boast were divorcing, it's okay.\n",
      "    H: All ten guys that proved to boast were divorcing.\n",
      "\n",
      "  1c: trigger='unembedded', presupposition='negated', label=2\n",
      "    P: All ten guys that proved to boast were divorcing.\n",
      "    H: There are exactly eleven guys that proved to boast.\n",
      "\n",
      "  2n: trigger='unembedded', presupposition='neutral', label=1\n",
      "    P: All ten guys that proved to boast were divorcing.\n",
      "    H: There are exactly ten senators that proved to boast.\n",
      "\n",
      "  3e: trigger='negated', presupposition='positive', label=0\n",
      "    P: All ten guys that proved to boast weren't divorcing.\n",
      "    H: There are exactly ten guys that proved to boast.\n",
      "\n",
      "  4c: trigger='negated', presupposition='negated', label=2\n",
      "    P: All ten guys that proved to boast weren't divorcing.\n",
      "    H: There are exactly eleven guys that proved to boast.\n",
      "\n",
      "  5n: trigger='negated', presupposition='neutral', label=1\n",
      "    P: All ten guys that proved to boast weren't divorcing.\n",
      "    H: There are exactly ten senators that proved to boast.\n",
      "\n",
      "  6e: trigger='interrogative', presupposition='positive', label=0\n",
      "    P: Were all ten guys that proved to boast divorcing?\n",
      "    H: There are exactly ten guys that proved to boast.\n",
      "\n",
      "  7c: trigger='interrogative', presupposition='negated', label=2\n",
      "    P: Were all ten guys that proved to boast divorcing?\n",
      "    H: There are exactly eleven guys that proved to boast.\n",
      "\n",
      "  8n: trigger='interrogative', presupposition='neutral', label=1\n",
      "    P: Were all ten guys that proved to boast divorcing?\n",
      "    H: There are exactly ten senators that proved to boast.\n",
      "\n",
      "  9e: trigger='modal', presupposition='positive', label=0\n",
      "    P: All ten guys that proved to boast might have been divorcing.\n",
      "    H: There are exactly ten guys that proved to boast.\n",
      "\n",
      "\n",
      "--- PARADIGM 1 (Section: presupposition_all_n_presupposition) ---\n",
      "Size: 19 samples\n",
      "  19e: trigger='unembedded', presupposition='positive', label=0\n",
      "  20c: trigger='unembedded', presupposition='negated', label=2\n",
      "  21n: trigger='unembedded', presupposition='neutral', label=1\n",
      "  22e: trigger='negated', presupposition='positive', label=0\n",
      "  23c: trigger='negated', presupposition='negated', label=2\n",
      "  24n: trigger='negated', presupposition='neutral', label=1\n",
      "  25e: trigger='interrogative', presupposition='positive', label=0\n",
      "  26c: trigger='interrogative', presupposition='negated', label=2\n",
      "  27n: trigger='interrogative', presupposition='neutral', label=1\n",
      "  28e: trigger='modal', presupposition='positive', label=0\n",
      "  29c: trigger='modal', presupposition='negated', label=2\n",
      "  30n: trigger='modal', presupposition='neutral', label=1\n",
      "  31e: trigger='conditional', presupposition='positive', label=0\n",
      "  32c: trigger='conditional', presupposition='negated', label=2\n",
      "  33n: trigger='conditional', presupposition='neutral', label=1\n",
      "  34c: trigger='Not_In_Example', trigger1='negated', trigger2='unembedded', presupposition='Not_In_Example', label=2\n",
      "  35n: trigger='Not_In_Example', trigger1='interrogative', trigger2='unembedded', presupposition='Not_In_Example', label=1\n",
      "  36n: trigger='Not_In_Example', trigger1='modal', trigger2='unembedded', presupposition='Not_In_Example', label=1\n",
      "  37n: trigger='Not_In_Example', trigger1='conditional', trigger2='unembedded', presupposition='Not_In_Example', label=1\n",
      "\n",
      "\n",
      "--- PARADIGM 2 (Section: presupposition_all_n_presupposition) ---\n",
      "Size: 19 samples\n",
      "  38e: trigger='unembedded', presupposition='positive', label=0\n",
      "  39c: trigger='unembedded', presupposition='negated', label=2\n",
      "  40n: trigger='unembedded', presupposition='neutral', label=1\n",
      "  41e: trigger='negated', presupposition='positive', label=0\n",
      "  42c: trigger='negated', presupposition='negated', label=2\n",
      "  43n: trigger='negated', presupposition='neutral', label=1\n",
      "  44e: trigger='interrogative', presupposition='positive', label=0\n",
      "  45c: trigger='interrogative', presupposition='negated', label=2\n",
      "  46n: trigger='interrogative', presupposition='neutral', label=1\n",
      "  47e: trigger='modal', presupposition='positive', label=0\n",
      "  48c: trigger='modal', presupposition='negated', label=2\n",
      "  49n: trigger='modal', presupposition='neutral', label=1\n",
      "  50e: trigger='conditional', presupposition='positive', label=0\n",
      "  51c: trigger='conditional', presupposition='negated', label=2\n",
      "  52n: trigger='conditional', presupposition='neutral', label=1\n",
      "  53c: trigger='Not_In_Example', trigger1='negated', trigger2='unembedded', presupposition='Not_In_Example', label=2\n",
      "  54n: trigger='Not_In_Example', trigger1='interrogative', trigger2='unembedded', presupposition='Not_In_Example', label=1\n",
      "  55n: trigger='Not_In_Example', trigger1='modal', trigger2='unembedded', presupposition='Not_In_Example', label=1\n",
      "  56n: trigger='Not_In_Example', trigger1='conditional', trigger2='unembedded', presupposition='Not_In_Example', label=1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "paradigmID\n",
       "0     19\n",
       "1     19\n",
       "2     19\n",
       "3     19\n",
       "4     19\n",
       "5     19\n",
       "6     19\n",
       "7     19\n",
       "8     19\n",
       "9     19\n",
       "10    19\n",
       "11    19\n",
       "12    19\n",
       "13    19\n",
       "14    19\n",
       "15    19\n",
       "16    19\n",
       "17    19\n",
       "18    19\n",
       "19    19\n",
       "20    19\n",
       "21    19\n",
       "22    19\n",
       "23    19\n",
       "24    19\n",
       "25    19\n",
       "26    19\n",
       "27    19\n",
       "28    19\n",
       "29    19\n",
       "30    19\n",
       "31    19\n",
       "32    19\n",
       "33    19\n",
       "34    19\n",
       "35    19\n",
       "36    19\n",
       "37    19\n",
       "38    19\n",
       "39    19\n",
       "40    19\n",
       "41    19\n",
       "42    19\n",
       "43    19\n",
       "44    19\n",
       "45    19\n",
       "46    19\n",
       "47    19\n",
       "48    19\n",
       "49    19\n",
       "50    19\n",
       "51    19\n",
       "52    12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dspy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Literal, List, Dict, Any\n",
    "import random\n",
    "from datasets import load_dataset, Dataset\n",
    "import evaluate\n",
    "from evaluate import load\n",
    "\n",
    "os.environ[\"XAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Configure DSPy environment\n",
    "lm = dspy.LM('xai/grok-3-mini', api_key=os.environ['XAI_API_KEY'])\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "print(\"DSPy configured with Grok-3-mini\")\n",
    "\n",
    "# Load the unified dataset (assuming you've already created it)\n",
    "print(\"Loading unified presupposition dataset...\")\n",
    "try:\n",
    "    unified_df = pd.read_csv('unified_presupposition_dataset.csv')\n",
    "    print(f\"Loaded unified dataset with {len(unified_df)} rows\")\n",
    "except FileNotFoundError:\n",
    "    print(\"unified_presupposition_dataset.csv not found. Loading from individual sections...\")\n",
    "    # Fallback: load from individual sections as done in 2.1\n",
    "    presupposition_sections = [\n",
    "        'presupposition_all_n_presupposition',\n",
    "        'presupposition_both_presupposition', \n",
    "        'presupposition_change_of_state',\n",
    "        'presupposition_cleft_existence',\n",
    "        'presupposition_cleft_uniqueness',\n",
    "        'presupposition_only_presupposition',\n",
    "        'presupposition_possessed_definites_existence',\n",
    "        'presupposition_possessed_definites_uniqueness',\n",
    "        'presupposition_question_presupposition'\n",
    "    ]\n",
    "    \n",
    "    combined_data = []\n",
    "    for section in presupposition_sections:\n",
    "        dataset = load_dataset(\"facebook/imppres\", section)\n",
    "        dataset_key = list(dataset.keys())[0]\n",
    "        df = dataset[dataset_key].to_pandas()\n",
    "        df['section'] = section\n",
    "        combined_data.append(df)\n",
    "        print(f\"Loaded {len(df)} rows from {section}\")\n",
    "    \n",
    "    unified_df = pd.concat(combined_data, ignore_index=True)\n",
    "    print(f\"Created unified dataset with {len(unified_df)} rows\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: SYSTEMATIC PARADIGM STRUCTURE EXPLORATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: EXPLORING PARADIGM STRUCTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def explore_paradigm_structure(df: pd.DataFrame, sample_paradigms: int = 3):\n",
    "    \"\"\"Systematically explore the structure of paradigms\"\"\"\n",
    "    \n",
    "    print(f\"Dataset overview:\")\n",
    "    print(f\"- Total samples: {len(df)}\")\n",
    "    print(f\"- Unique paradigms: {df['paradigmID'].nunique()}\")\n",
    "    print(f\"- Sections: {df['section'].unique()}\")\n",
    "    \n",
    "    # Check paradigm sizes\n",
    "    paradigm_sizes = df.groupby('paradigmID').size()\n",
    "    print(f\"\\nParadigm size distribution:\")\n",
    "    print(paradigm_sizes.value_counts().sort_index())\n",
    "    \n",
    "    # Explore transformation types by examining trigger fields\n",
    "    print(f\"\\nTransformation analysis:\")\n",
    "    print(f\"- Unique 'trigger' values: {sorted(df['trigger'].unique())}\")\n",
    "    print(f\"- Unique 'trigger1' values: {sorted(df['trigger1'].unique())}\")\n",
    "    print(f\"- Unique 'trigger2' values: {sorted(df['trigger2'].unique())}\")\n",
    "    print(f\"- Unique 'presupposition' values: {sorted(df['presupposition'].unique())}\")\n",
    "    \n",
    "    # Label distribution\n",
    "    print(f\"\\nLabel distribution:\")\n",
    "    print(df['gold_label'].value_counts().sort_index())\n",
    "    \n",
    "    # Sample a few paradigms for detailed analysis\n",
    "    sample_paradigm_ids = df['paradigmID'].unique()[:sample_paradigms]\n",
    "    \n",
    "    for i, paradigm_id in enumerate(sample_paradigm_ids):\n",
    "        paradigm_samples = df[df['paradigmID'] == paradigm_id].sort_values('pairID')\n",
    "        print(f\"\\n--- PARADIGM {paradigm_id} (Section: {paradigm_samples['section'].iloc[0]}) ---\")\n",
    "        print(f\"Size: {len(paradigm_samples)} samples\")\n",
    "        \n",
    "        # Show the transformation pattern\n",
    "        for idx, row in paradigm_samples.iterrows():\n",
    "            trigger_info = f\"trigger='{row['trigger']}'\"\n",
    "            if row['trigger1'] != 'Not_In_Example':\n",
    "                trigger_info += f\", trigger1='{row['trigger1']}'\"\n",
    "            if row['trigger2'] != 'Not_In_Example':\n",
    "                trigger_info += f\", trigger2='{row['trigger2']}'\"\n",
    "            \n",
    "            presup_info = f\"presupposition='{row['presupposition']}'\"\n",
    "            \n",
    "            print(f\"  {row['pairID']}: {trigger_info}, {presup_info}, label={row['gold_label']}\")\n",
    "            \n",
    "            if i == 0:  # Show full text for first paradigm only\n",
    "                print(f\"    P: {row['premise']}\")\n",
    "                print(f\"    H: {row['hypothesis']}\")\n",
    "                print()\n",
    "        \n",
    "        if i > 0:  # Add spacing for subsequent paradigms\n",
    "            print()\n",
    "    \n",
    "    return paradigm_sizes\n",
    "\n",
    "# Explore with a small subset first for faster iteration\n",
    "print(\"Working with subset for initial exploration...\")\n",
    "subset_df = unified_df.head(1000)  # Start with first 1000 samples for testing\n",
    "explore_paradigm_structure(subset_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c13b3ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 2: IDENTIFYING THE 19 TRANSFORMATION TYPES\n",
      "============================================================\n",
      "Found 19 unique transformation types:\n",
      " 1. trigger:unembedded | presup:positive (53 samples)\n",
      " 2. trigger:interrogative | presup:negated (53 samples)\n",
      " 3. trigger:modal | presup:neutral (53 samples)\n",
      " 4. trigger:modal | presup:negated (53 samples)\n",
      " 5. trigger:unembedded | presup:negated (53 samples)\n",
      " 6. trigger:interrogative | presup:neutral (53 samples)\n",
      " 7. trigger:modal | presup:positive (53 samples)\n",
      " 8. trigger:interrogative | presup:positive (53 samples)\n",
      " 9. trigger:negated | presup:neutral (53 samples)\n",
      "10. trigger:negated | presup:negated (53 samples)\n",
      "11. trigger:negated | presup:positive (53 samples)\n",
      "12. trigger:unembedded | presup:neutral (53 samples)\n",
      "13. trigger:conditional | presup:positive (52 samples)\n",
      "14. trigger:conditional | presup:negated (52 samples)\n",
      "15. trigger:conditional | presup:neutral (52 samples)\n",
      "16. trigger1:negated | trigger2:unembedded (52 samples)\n",
      "17. trigger1:interrogative | trigger2:unembedded (52 samples)\n",
      "18. trigger1:modal | trigger2:unembedded (52 samples)\n",
      "19. trigger1:conditional | trigger2:unembedded (52 samples)\n",
      "\n",
      "Transformations in sample paradigm: 19\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: IDENTIFY THE 19 TRANSFORMATION TYPES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: IDENTIFYING THE 19 TRANSFORMATION TYPES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def analyze_transformation_types(df: pd.DataFrame):\n",
    "    \"\"\"Identify and categorize the 19 transformation types\"\"\"\n",
    "    \n",
    "    # Create a combined transformation identifier\n",
    "    def get_transformation_signature(row):\n",
    "        \"\"\"Create a unique signature for each transformation type\"\"\"\n",
    "        sig_parts = []\n",
    "        \n",
    "        # Primary trigger\n",
    "        if row['trigger'] != 'Not_In_Example':\n",
    "            sig_parts.append(f\"trigger:{row['trigger']}\")\n",
    "        \n",
    "        # Secondary triggers\n",
    "        if row['trigger1'] != 'Not_In_Example':\n",
    "            sig_parts.append(f\"trigger1:{row['trigger1']}\")\n",
    "        if row['trigger2'] != 'Not_In_Example':\n",
    "            sig_parts.append(f\"trigger2:{row['trigger2']}\")\n",
    "            \n",
    "        # Presupposition status\n",
    "        if row['presupposition'] != 'Not_In_Example':\n",
    "            sig_parts.append(f\"presup:{row['presupposition']}\")\n",
    "            \n",
    "        return \" | \".join(sig_parts) if sig_parts else \"base\"\n",
    "    \n",
    "    # Apply transformation signature to subset\n",
    "    df_sample = df.copy()\n",
    "    df_sample['transformation_signature'] = df_sample.apply(get_transformation_signature, axis=1)\n",
    "    \n",
    "    # Count transformation types\n",
    "    transformation_counts = df_sample['transformation_signature'].value_counts()\n",
    "    print(f\"Found {len(transformation_counts)} unique transformation types:\")\n",
    "    \n",
    "    for i, (transformation, count) in enumerate(transformation_counts.items(), 1):\n",
    "        print(f\"{i:2d}. {transformation} ({count} samples)\")\n",
    "    \n",
    "    # Verify we have 19 transformations per paradigm\n",
    "    sample_paradigm = df_sample[df_sample['paradigmID'] == df_sample['paradigmID'].iloc[0]]\n",
    "    sample_transformations = sample_paradigm['transformation_signature'].unique()\n",
    "    print(f\"\\nTransformations in sample paradigm: {len(sample_transformations)}\")\n",
    "    \n",
    "    return transformation_counts, df_sample\n",
    "\n",
    "transformation_counts, subset_with_signatures = analyze_transformation_types(subset_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53cde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 3: IMPLEMENTING DSPy CLASSIFIER\n",
      "============================================================\n",
      "Initializing PresuppositionNLI classifier...\n",
      "\n",
      "Testing classifier on sample data...\n",
      "\n",
      "--- Test Sample 1 ---\n",
      "Premise: All ten guys that proved to boast were divorcing.\n",
      "Hypothesis: There are exactly ten guys that proved to boast.\n",
      "Gold label: 0\n",
      "Predicted: entailment\n",
      "Reasoning: The premise states \"All ten guys that proved to boast were divorcing,\" which presupposes the existence of exactly ten guys who proved to boast. This is evident from the phrase \"all ten,\" as it quantifies the group precisely as ten, implying that the set of guys who proved to boast is exactly that number. The hypothesis directly asserts \"There are exactly ten guys that proved to boast,\" which aligns with this presupposition. Therefore, the premise entails the hypothesis because the presupposition in the premise logically implies the statement in the hypothesis.\n",
      "Numeric prediction: 0 (Gold: 0)\n",
      "\n",
      "--- Test Sample 2 ---\n",
      "Premise: All ten guys that proved to boast were divorcing.\n",
      "Hypothesis: There are exactly eleven guys that proved to boast.\n",
      "Gold label: 2\n",
      "Predicted: contradiction\n",
      "Reasoning: The premise states \"All ten guys that proved to boast were divorcing,\" which presupposes and asserts that there are exactly ten guys who proved to boast. This specific quantity (ten) is a key presupposition of the premise. The hypothesis, however, claims that there are exactly eleven guys who proved to boast. These two statements involve conflicting quantities: the premise entails a total of ten such guys, while the hypothesis requires a total of eleven. This direct conflict in the presupposed and asserted numbers means the premise cannot be true if the hypothesis is true, leading to a contradiction.\n",
      "Numeric prediction: 2 (Gold: 2)\n",
      "\n",
      "--- Test Sample 3 ---\n",
      "Premise: All ten guys that proved to boast were divorcing.\n",
      "Hypothesis: There are exactly ten senators that proved to boast.\n",
      "Gold label: 1\n",
      "Predicted: neutral\n",
      "Reasoning: The premise states that there are exactly ten guys who proved to boast and that all of them were divorcing. This presupposes the existence of exactly ten guys with this characteristic. However, the hypothesis claims that there are exactly ten senators who proved to boast. The key difference lies in the terms \"guys\" versus \"senators\"; the premise does not specify that these guys are senators, which is a crucial presupposition in the hypothesis. The premise could be true even if the guys are not senators, meaning the hypothesis is neither definitively true nor false based on the premise alone. Therefore, the relationship is neutral, as the premise does not entail or contradict the additional specification in the hypothesis.\n",
      "Numeric prediction: 1 (Gold: 1)\n",
      "\n",
      "Classifier testing complete!\n",
      "\n",
      "============================================================\n",
      "STEP 1-3 COMPLETE - PREPARATION FOR FULL PIPELINE\n",
      "============================================================\n",
      "Summary of findings:\n",
      "- Working with 1000 samples\n",
      "- Identified 19 transformation types\n",
      "- DSPy classifier successfully initialized and tested\n",
      "- Ready to proceed with full paradigm consistency pipeline\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: DSPy CLASSIFIER IMPLEMENTATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: IMPLEMENTING DSPy CLASSIFIER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class NLIClassification(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Perform Natural Language Inference to determine the relationship between premise and hypothesis.\n",
    "    Focus on presupposition entailment patterns.\n",
    "    \"\"\"\n",
    "    premise: str = dspy.InputField(desc=\"The premise statement\")\n",
    "    hypothesis: str = dspy.InputField(desc=\"The hypothesis statement\") \n",
    "    reasoning: str = dspy.OutputField(desc=\"Step-by-step reasoning about the entailment relationship, focusing on presuppositions\")\n",
    "    label: Literal['entailment', 'neutral', 'contradiction'] = dspy.OutputField(desc=\"The entailment relationship: entailment (0), neutral (1), or contradiction (2)\")\n",
    "\n",
    "class PresuppositionNLI(dspy.Module):\n",
    "    \"\"\"DSPy module for presupposition-aware NLI classification\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classify = dspy.ChainOfThought(NLIClassification)\n",
    "    \n",
    "    def forward(self, premise: str, hypothesis: str):\n",
    "        result = self.classify(premise=premise, hypothesis=hypothesis)\n",
    "        return result\n",
    "\n",
    "# Initialize classifier\n",
    "print(\"Initializing PresuppositionNLI classifier...\")\n",
    "classifier = PresuppositionNLI()\n",
    "\n",
    "# Test on a few samples\n",
    "print(\"\\nTesting classifier on sample data...\")\n",
    "test_samples = subset_df.head(3)\n",
    "\n",
    "for i, row in test_samples.iterrows():\n",
    "    print(f\"\\n--- Test Sample {i+1} ---\")\n",
    "    print(f\"Premise: {row['premise']}\")\n",
    "    print(f\"Hypothesis: {row['hypothesis']}\")\n",
    "    print(f\"Gold label: {row['gold_label']}\")\n",
    "    \n",
    "    try:\n",
    "        result = classifier(premise=row['premise'], hypothesis=row['hypothesis'])\n",
    "        print(f\"Predicted: {result.label}\")\n",
    "        print(f\"Reasoning: {result.reasoning}\")\n",
    "        \n",
    "        # Convert label to numeric for comparison\n",
    "        label_map = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n",
    "        pred_numeric = label_map.get(result.label, -1)\n",
    "        print(f\"Numeric prediction: {pred_numeric} (Gold: {row['gold_label']})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during classification: {e}\")\n",
    "\n",
    "print(\"\\nClassifier testing complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "236f8b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 4: INDIVIDUAL INFERENCE PIPELINE\n",
      "============================================================\n",
      "Preparing data for individual inference...\n",
      "Preparing paradigm data...\n",
      "- Total samples: 1000\n",
      "- Unique paradigms: 53\n",
      "- Paradigm sizes: Counter({19: 52, 12: 1})\n",
      "- Shuffling within paradigms: True\n",
      "- Total samples after processing: 1000\n",
      "\n",
      "Running individual inference (limited batch for testing)...\n",
      "Processing 100 samples (limited for testing)\n",
      "  Progress: 0/100 samples processed\n",
      "  Progress: 50/100 samples processed\n",
      "\n",
      "Inference complete!\n",
      "- Successful predictions: 100\n",
      "- Errors: 0\n",
      "- Overall accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: INDIVIDUAL INFERENCE PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: INDIVIDUAL INFERENCE PIPELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def prepare_paradigm_data(df: pd.DataFrame, shuffle_within_paradigms: bool = True):\n",
    "    \"\"\"Prepare data for individual inference with paradigm shuffling\"\"\"\n",
    "    \n",
    "    print(f\"Preparing paradigm data...\")\n",
    "    print(f\"- Total samples: {len(df)}\")\n",
    "    print(f\"- Unique paradigms: {df['paradigmID'].nunique()}\")\n",
    "    \n",
    "    # Group by paradigmID\n",
    "    paradigms = {}\n",
    "    for _, row in df.iterrows():\n",
    "        paradigm_id = row['paradigmID']\n",
    "        if paradigm_id not in paradigms:\n",
    "            paradigms[paradigm_id] = []\n",
    "        paradigms[paradigm_id].append(row.to_dict())\n",
    "    \n",
    "    # Verify paradigm sizes and shuffle\n",
    "    paradigm_stats = []\n",
    "    for paradigm_id, samples in paradigms.items():\n",
    "        paradigm_stats.append(len(samples))\n",
    "        if shuffle_within_paradigms:\n",
    "            random.shuffle(samples)\n",
    "    \n",
    "    print(f\"- Paradigm sizes: {Counter(paradigm_stats)}\")\n",
    "    print(f\"- Shuffling within paradigms: {shuffle_within_paradigms}\")\n",
    "    \n",
    "    # Flatten back to individual samples\n",
    "    all_samples = []\n",
    "    for paradigm_samples in paradigms.values():\n",
    "        all_samples.extend(paradigm_samples)\n",
    "    \n",
    "    print(f\"- Total samples after processing: {len(all_samples)}\")\n",
    "    \n",
    "    return all_samples, paradigms\n",
    "\n",
    "def run_individual_inference(samples: List[Dict], classifier, max_samples: int = None):\n",
    "    \"\"\"Run individual inference on each sample\"\"\"\n",
    "    \n",
    "    if max_samples:\n",
    "        samples = samples[:max_samples]\n",
    "        print(f\"Processing {len(samples)} samples (limited for testing)\")\n",
    "    else:\n",
    "        print(f\"Processing {len(samples)} samples\")\n",
    "    \n",
    "    results = []\n",
    "    errors = []\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        if i % 50 == 0:  # Progress indicator\n",
    "            print(f\"  Progress: {i}/{len(samples)} samples processed\")\n",
    "        \n",
    "        try:\n",
    "            # Run inference\n",
    "            prediction = classifier(\n",
    "                premise=sample['premise'], \n",
    "                hypothesis=sample['hypothesis']\n",
    "            )\n",
    "            \n",
    "            # Convert label to numeric \n",
    "            label_map = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n",
    "            pred_numeric = label_map.get(prediction.label, -1)\n",
    "            \n",
    "            # Store result with paradigm metadata\n",
    "            result = {\n",
    "                'sample_id': sample.get('UID', f\"sample_{i}\"),\n",
    "                'paradigm_id': sample['paradigmID'],\n",
    "                'pair_id': sample['pairID'], \n",
    "                'section': sample['section'],\n",
    "                'transformation_signature': get_transformation_signature(sample),\n",
    "                'gold_label': sample['gold_label'],\n",
    "                'predicted_label': prediction.label,\n",
    "                'predicted_numeric': pred_numeric,\n",
    "                'reasoning': prediction.reasoning,\n",
    "                'premise': sample['premise'],\n",
    "                'hypothesis': sample['hypothesis'],\n",
    "                'trigger': sample['trigger'],\n",
    "                'trigger1': sample['trigger1'],\n",
    "                'trigger2': sample['trigger2'],\n",
    "                'presupposition': sample['presupposition']\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_info = {\n",
    "                'sample_index': i,\n",
    "                'paradigm_id': sample['paradigmID'],\n",
    "                'error': str(e)\n",
    "            }\n",
    "            errors.append(error_info)\n",
    "            print(f\"  Error on sample {i}: {e}\")\n",
    "    \n",
    "    print(f\"\\nInference complete!\")\n",
    "    print(f\"- Successful predictions: {len(results)}\")\n",
    "    print(f\"- Errors: {len(errors)}\")\n",
    "    \n",
    "    if len(results) > 0:\n",
    "        # Calculate basic accuracy\n",
    "        correct = sum(1 for r in results if r['predicted_numeric'] == r['gold_label'])\n",
    "        accuracy = correct / len(results)\n",
    "        print(f\"- Overall accuracy: {accuracy:.3f}\")\n",
    "    \n",
    "    return results, errors\n",
    "\n",
    "# Use transformation signature function from earlier\n",
    "def get_transformation_signature(sample):\n",
    "    \"\"\"Create a unique signature for each transformation type\"\"\"\n",
    "    sig_parts = []\n",
    "    \n",
    "    # Primary trigger\n",
    "    if sample['trigger'] != 'Not_In_Example':\n",
    "        sig_parts.append(f\"trigger:{sample['trigger']}\")\n",
    "    \n",
    "    # Secondary triggers\n",
    "    if sample['trigger1'] != 'Not_In_Example':\n",
    "        sig_parts.append(f\"trigger1:{sample['trigger1']}\")\n",
    "    if sample['trigger2'] != 'Not_In_Example':\n",
    "        sig_parts.append(f\"trigger2:{sample['trigger2']}\")\n",
    "        \n",
    "    # Presupposition status\n",
    "    if sample['presupposition'] != 'Not_In_Example':\n",
    "        sig_parts.append(f\"presup:{sample['presupposition']}\")\n",
    "        \n",
    "    return \" | \".join(sig_parts) if sig_parts else \"base\"\n",
    "\n",
    "# Prepare data for inference (start with subset for testing)\n",
    "print(\"Preparing data for individual inference...\")\n",
    "all_samples, paradigms_dict = prepare_paradigm_data(subset_df, shuffle_within_paradigms=True)\n",
    "\n",
    "# Run individual inference on a smaller batch first\n",
    "print(\"\\nRunning individual inference (limited batch for testing)...\")\n",
    "results, errors = run_individual_inference(all_samples, classifier, max_samples=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8de02119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 5: PARADIGM-LEVEL CONSISTENCY ANALYSIS\n",
      "============================================================\n",
      "Running paradigm consistency analysis...\n",
      "Grouped results into 6 paradigms\n",
      "Paradigm size distribution: Counter({19: 5, 5: 1})\n",
      "\n",
      "Completed consistency analysis for 6 paradigms\n",
      "\n",
      "Overall Paradigm Statistics:\n",
      "- Average accuracy: 0.982\n",
      "- Average majority consistency: 0.435\n",
      "- Average entropy consistency: 0.031\n",
      "- Perfect consistency rate: 0.000\n",
      "\n",
      "Combined Scores:\n",
      "- Balanced (α=0.5): 0.709\n",
      "- Accuracy-focused (α=0.7): 0.818\n",
      "- Consistency-focused (α=0.3): 0.599\n",
      "\n",
      "Detailed Analysis for First 3 Paradigms:\n",
      "\n",
      "--- Paradigm 0 (Section: presupposition_all_n_presupposition) ---\n",
      "Size: 19\n",
      "Accuracy: 0.947\n",
      "Majority consistency: 0.474\n",
      "Entropy consistency: 0.048\n",
      "Perfect consistency: False\n",
      "Prediction distribution: {0: 4, 2: 6, 1: 9}\n",
      "Gold distribution: {0: 5, 2: 6, 1: 8}\n",
      "Transformation accuracy:\n",
      "  trigger:interrogative | presup:positive: 1.000 (1/1)\n",
      "  trigger:negated | presup:negated: 1.000 (1/1)\n",
      "  trigger:conditional | presup:positive: 0.000 (0/1)\n",
      "  trigger:conditional | presup:neutral: 1.000 (1/1)\n",
      "  trigger:modal | presup:neutral: 1.000 (1/1)\n",
      "  trigger:modal | presup:positive: 1.000 (1/1)\n",
      "  trigger1:interrogative | trigger2:unembedded: 1.000 (1/1)\n",
      "  trigger1:negated | trigger2:unembedded: 1.000 (1/1)\n",
      "  trigger1:conditional | trigger2:unembedded: 1.000 (1/1)\n",
      "  trigger:interrogative | presup:neutral: 1.000 (1/1)\n",
      "  trigger:interrogative | presup:negated: 1.000 (1/1)\n",
      "  trigger:unembedded | presup:neutral: 1.000 (1/1)\n",
      "  trigger:unembedded | presup:negated: 1.000 (1/1)\n",
      "  trigger:negated | presup:neutral: 1.000 (1/1)\n",
      "  trigger:unembedded | presup:positive: 1.000 (1/1)\n",
      "  trigger:conditional | presup:negated: 1.000 (1/1)\n",
      "  trigger:negated | presup:positive: 1.000 (1/1)\n",
      "  trigger1:modal | trigger2:unembedded: 1.000 (1/1)\n",
      "  trigger:modal | presup:negated: 1.000 (1/1)\n",
      "\n",
      "--- Paradigm 1 (Section: presupposition_all_n_presupposition) ---\n",
      "Size: 19\n",
      "Accuracy: 0.947\n",
      "Majority consistency: 0.474\n",
      "Entropy consistency: 0.048\n",
      "Perfect consistency: False\n",
      "Prediction distribution: {1: 9, 2: 6, 0: 4}\n",
      "Gold distribution: {1: 8, 2: 6, 0: 5}\n",
      "Transformation accuracy:\n",
      "  trigger:interrogative | presup:neutral: 1.000 (1/1)\n",
      "  trigger:interrogative | presup:negated: 1.000 (1/1)\n",
      "  trigger:unembedded | presup:positive: 1.000 (1/1)\n",
      "  trigger:conditional | presup:neutral: 1.000 (1/1)\n",
      "  trigger:conditional | presup:negated: 1.000 (1/1)\n",
      "  trigger:unembedded | presup:negated: 1.000 (1/1)\n",
      "  trigger1:conditional | trigger2:unembedded: 1.000 (1/1)\n",
      "  trigger:modal | presup:positive: 1.000 (1/1)\n",
      "  trigger:negated | presup:positive: 1.000 (1/1)\n",
      "  trigger:negated | presup:negated: 1.000 (1/1)\n",
      "  trigger:modal | presup:neutral: 1.000 (1/1)\n",
      "  trigger1:modal | trigger2:unembedded: 1.000 (1/1)\n",
      "  trigger:negated | presup:neutral: 1.000 (1/1)\n",
      "  trigger:unembedded | presup:neutral: 1.000 (1/1)\n",
      "  trigger:conditional | presup:positive: 0.000 (0/1)\n",
      "  trigger:modal | presup:negated: 1.000 (1/1)\n",
      "  trigger:interrogative | presup:positive: 1.000 (1/1)\n",
      "  trigger1:interrogative | trigger2:unembedded: 1.000 (1/1)\n",
      "  trigger1:negated | trigger2:unembedded: 1.000 (1/1)\n",
      "\n",
      "--- Paradigm 2 (Section: presupposition_all_n_presupposition) ---\n",
      "Size: 19\n",
      "Accuracy: 1.000\n",
      "Majority consistency: 0.421\n",
      "Entropy consistency: 0.017\n",
      "Perfect consistency: False\n",
      "Prediction distribution: {0: 5, 1: 8, 2: 6}\n",
      "Gold distribution: {0: 5, 1: 8, 2: 6}\n",
      "Transformation accuracy:\n",
      "  trigger:interrogative | presup:positive: 1.000 (1/1)\n",
      "  trigger1:modal | trigger2:unembedded: 1.000 (1/1)\n",
      "  trigger:modal | presup:positive: 1.000 (1/1)\n",
      "  trigger1:conditional | trigger2:unembedded: 1.000 (1/1)\n",
      "  trigger:conditional | presup:neutral: 1.000 (1/1)\n",
      "  trigger:negated | presup:negated: 1.000 (1/1)\n",
      "  trigger:negated | presup:neutral: 1.000 (1/1)\n",
      "  trigger:negated | presup:positive: 1.000 (1/1)\n",
      "  trigger1:negated | trigger2:unembedded: 1.000 (1/1)\n",
      "  trigger:modal | presup:neutral: 1.000 (1/1)\n",
      "  trigger:unembedded | presup:negated: 1.000 (1/1)\n",
      "  trigger:interrogative | presup:negated: 1.000 (1/1)\n",
      "  trigger:conditional | presup:negated: 1.000 (1/1)\n",
      "  trigger:unembedded | presup:positive: 1.000 (1/1)\n",
      "  trigger:interrogative | presup:neutral: 1.000 (1/1)\n",
      "  trigger:modal | presup:negated: 1.000 (1/1)\n",
      "  trigger1:interrogative | trigger2:unembedded: 1.000 (1/1)\n",
      "  trigger:unembedded | presup:neutral: 1.000 (1/1)\n",
      "  trigger:conditional | presup:positive: 1.000 (1/1)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: PARADIGM-LEVEL CONSISTENCY ANALYSIS FRAMEWORK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: PARADIGM-LEVEL CONSISTENCY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def group_results_by_paradigm(results: List[Dict]):\n",
    "    \"\"\"Group inference results back by paradigmID\"\"\"\n",
    "    \n",
    "    paradigm_results = defaultdict(list)\n",
    "    \n",
    "    for result in results:\n",
    "        paradigm_id = result['paradigm_id']\n",
    "        paradigm_results[paradigm_id].append(result)\n",
    "    \n",
    "    print(f\"Grouped results into {len(paradigm_results)} paradigms\")\n",
    "    \n",
    "    # Verify paradigm sizes\n",
    "    paradigm_sizes = [len(samples) for samples in paradigm_results.values()]\n",
    "    print(f\"Paradigm size distribution: {Counter(paradigm_sizes)}\")\n",
    "    \n",
    "    return dict(paradigm_results)\n",
    "\n",
    "def calculate_paradigm_consistency_metrics(paradigm_samples: List[Dict]):\n",
    "    \"\"\"Calculate multiple consistency metrics for a single paradigm\"\"\"\n",
    "    \n",
    "    if len(paradigm_samples) == 0:\n",
    "        return None\n",
    "    \n",
    "    predictions = [s['predicted_numeric'] for s in paradigm_samples]\n",
    "    gold_labels = [s['gold_label'] for s in paradigm_samples]\n",
    "    \n",
    "    # Basic info\n",
    "    paradigm_id = paradigm_samples[0]['paradigm_id']\n",
    "    section = paradigm_samples[0]['section']\n",
    "    paradigm_size = len(paradigm_samples)\n",
    "    \n",
    "    # Accuracy metrics\n",
    "    correct_predictions = sum(1 for p, g in zip(predictions, gold_labels) if p == g)\n",
    "    paradigm_accuracy = correct_predictions / len(predictions)\n",
    "    \n",
    "    # Consistency metrics\n",
    "    pred_counts = Counter(predictions)\n",
    "    gold_counts = Counter(gold_labels)\n",
    "    \n",
    "    # 1. Majority vote consistency (what % agree with majority prediction)\n",
    "    majority_pred = pred_counts.most_common(1)[0][0]\n",
    "    majority_consistency = pred_counts[majority_pred] / len(predictions)\n",
    "    \n",
    "    # 2. Perfect consistency (all predictions identical)\n",
    "    perfect_consistency = len(set(predictions)) == 1\n",
    "    \n",
    "    # 3. Entropy-based consistency (lower entropy = higher consistency)\n",
    "    prediction_entropy = 0\n",
    "    total = len(predictions)\n",
    "    for count in pred_counts.values():\n",
    "        prob = count / total\n",
    "        if prob > 0:\n",
    "            prediction_entropy -= prob * np.log2(prob)\n",
    "    \n",
    "    # Normalize entropy (0 = perfect consistency, 1 = maximum inconsistency)\n",
    "    max_entropy = np.log2(min(3, len(predictions)))  # 3 possible labels\n",
    "    normalized_entropy = prediction_entropy / max_entropy if max_entropy > 0 else 0\n",
    "    entropy_consistency = 1 - normalized_entropy\n",
    "    \n",
    "    # 4. Agreement with gold label pattern\n",
    "    # Check if prediction pattern matches gold pattern structure\n",
    "    pred_pattern = tuple(sorted(pred_counts.items()))\n",
    "    gold_pattern = tuple(sorted(gold_counts.items()))\n",
    "    pattern_match = pred_pattern == gold_pattern\n",
    "    \n",
    "    # 5. Transformation-specific analysis\n",
    "    transformation_analysis = {}\n",
    "    for sample in paradigm_samples:\n",
    "        trans_sig = sample['transformation_signature']\n",
    "        if trans_sig not in transformation_analysis:\n",
    "            transformation_analysis[trans_sig] = {\n",
    "                'correct': 0, 'total': 0, 'predicted_labels': []\n",
    "            }\n",
    "        \n",
    "        is_correct = sample['predicted_numeric'] == sample['gold_label']\n",
    "        transformation_analysis[trans_sig]['correct'] += int(is_correct)\n",
    "        transformation_analysis[trans_sig]['total'] += 1\n",
    "        transformation_analysis[trans_sig]['predicted_labels'].append(sample['predicted_numeric'])\n",
    "    \n",
    "    return {\n",
    "        'paradigm_id': paradigm_id,\n",
    "        'section': section,\n",
    "        'paradigm_size': paradigm_size,\n",
    "        'accuracy': paradigm_accuracy,\n",
    "        'correct_count': correct_predictions,\n",
    "        'majority_pred': majority_pred,\n",
    "        'majority_consistency': majority_consistency,\n",
    "        'perfect_consistency': perfect_consistency,\n",
    "        'entropy_consistency': entropy_consistency,\n",
    "        'pattern_match': pattern_match,\n",
    "        'prediction_distribution': dict(pred_counts),\n",
    "        'gold_distribution': dict(gold_counts),\n",
    "        'transformation_analysis': transformation_analysis,\n",
    "        'samples': paradigm_samples\n",
    "    }\n",
    "\n",
    "def calculate_combined_consistency_score(accuracy: float, consistency: float, alpha: float = 0.7):\n",
    "    \"\"\"\n",
    "    Combine accuracy and consistency into a single score\n",
    "    alpha: weight for accuracy (higher alpha = more weight on accuracy)\n",
    "    \"\"\"\n",
    "    return alpha * accuracy + (1 - alpha) * consistency\n",
    "\n",
    "def analyze_all_paradigms(results: List[Dict]):\n",
    "    \"\"\"Analyze consistency across all paradigms\"\"\"\n",
    "    \n",
    "    # Group by paradigm\n",
    "    paradigm_results = group_results_by_paradigm(results)\n",
    "    \n",
    "    # Calculate metrics for each paradigm\n",
    "    paradigm_analyses = []\n",
    "    \n",
    "    for paradigm_id, samples in paradigm_results.items():\n",
    "        analysis = calculate_paradigm_consistency_metrics(samples)\n",
    "        if analysis:\n",
    "            paradigm_analyses.append(analysis)\n",
    "    \n",
    "    print(f\"\\nCompleted consistency analysis for {len(paradigm_analyses)} paradigms\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    if len(paradigm_analyses) > 0:\n",
    "        overall_accuracy = np.mean([p['accuracy'] for p in paradigm_analyses])\n",
    "        overall_majority_consistency = np.mean([p['majority_consistency'] for p in paradigm_analyses])\n",
    "        overall_entropy_consistency = np.mean([p['entropy_consistency'] for p in paradigm_analyses])\n",
    "        perfect_consistency_rate = np.mean([p['perfect_consistency'] for p in paradigm_analyses])\n",
    "        \n",
    "        print(f\"\\nOverall Paradigm Statistics:\")\n",
    "        print(f\"- Average accuracy: {overall_accuracy:.3f}\")\n",
    "        print(f\"- Average majority consistency: {overall_majority_consistency:.3f}\")\n",
    "        print(f\"- Average entropy consistency: {overall_entropy_consistency:.3f}\")\n",
    "        print(f\"- Perfect consistency rate: {perfect_consistency_rate:.3f}\")\n",
    "        \n",
    "        # Combined scores with different weightings\n",
    "        combined_score_balanced = calculate_combined_consistency_score(overall_accuracy, overall_majority_consistency, alpha=0.5)\n",
    "        combined_score_accuracy_focused = calculate_combined_consistency_score(overall_accuracy, overall_majority_consistency, alpha=0.7)\n",
    "        combined_score_consistency_focused = calculate_combined_consistency_score(overall_accuracy, overall_majority_consistency, alpha=0.3)\n",
    "        \n",
    "        print(f\"\\nCombined Scores:\")\n",
    "        print(f\"- Balanced (α=0.5): {combined_score_balanced:.3f}\")\n",
    "        print(f\"- Accuracy-focused (α=0.7): {combined_score_accuracy_focused:.3f}\")\n",
    "        print(f\"- Consistency-focused (α=0.3): {combined_score_consistency_focused:.3f}\")\n",
    "    \n",
    "    return paradigm_analyses\n",
    "\n",
    "# Run consistency analysis on current results\n",
    "if len(results) > 0:\n",
    "    print(\"Running paradigm consistency analysis...\")\n",
    "    paradigm_analyses = analyze_all_paradigms(results)\n",
    "    \n",
    "    # Show detailed analysis for first few paradigms\n",
    "    print(f\"\\nDetailed Analysis for First 3 Paradigms:\")\n",
    "    for i, analysis in enumerate(paradigm_analyses[:3]):\n",
    "        print(f\"\\n--- Paradigm {analysis['paradigm_id']} (Section: {analysis['section']}) ---\")\n",
    "        print(f\"Size: {analysis['paradigm_size']}\")\n",
    "        print(f\"Accuracy: {analysis['accuracy']:.3f}\")\n",
    "        print(f\"Majority consistency: {analysis['majority_consistency']:.3f}\")\n",
    "        print(f\"Entropy consistency: {analysis['entropy_consistency']:.3f}\")\n",
    "        print(f\"Perfect consistency: {analysis['perfect_consistency']}\")\n",
    "        print(f\"Prediction distribution: {analysis['prediction_distribution']}\")\n",
    "        print(f\"Gold distribution: {analysis['gold_distribution']}\")\n",
    "        \n",
    "        # Show transformation-specific accuracy\n",
    "        print(f\"Transformation accuracy:\")\n",
    "        for trans, stats in analysis['transformation_analysis'].items():\n",
    "            acc = stats['correct'] / stats['total'] if stats['total'] > 0 else 0\n",
    "            print(f\"  {trans}: {acc:.3f} ({stats['correct']}/{stats['total']})\")\n",
    "\n",
    "else:\n",
    "    print(\"No results available for consistency analysis\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv - hw2)",
   "language": "python",
   "name": "hw2-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
